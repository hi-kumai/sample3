---

layout: default
title: "連続最適化入門"
description: "連続最適化（微分可能な目的関数を持つ最適化問題）の基礎を分かりやすく解説する入門ページ。"
permalink: /index.html
----------------------

# 連続最適化入門

このページは，連続最適化（continuous optimization）── 連続変数上で定義された最適化問題（微分可能な目的関数・制約を含む場合が多い）── の基礎を系統的に学ぶための入門ガイドである．理論の核となる概念，代表的なアルゴリズム，実装例，演習問題，さらなる学習リソースを順に示す．

---

## 目次

1. はじめに（何を解くか）
2. 前提知識
3. 基本概念と表記法
4. 非制約最適化（基礎とアルゴリズム）
5. 制約付き最適化（代表的手法）
6. 数値実装とライブラリ
7. 演習問題
8. 参考文献・学習リソース

---

## 1. はじめに（何を解くか）

連続最適化は，連続変数 (x\in\mathbb{R}^n) に対して目的関数 (f(x)) を最小化（または最大化）する問題を扱う．一般形は次の通りである：

[\begin{aligned}
\min_{x\in\mathbb{R}^n} &\quad f(x)\
\text{s.t.} &\quad g_i(x) \le 0 \quad (i=1,\dots,m)\
&\quad h_j(x) = 0 \quad (j=1,\dots,p)
\end{aligned}]

ここで，(f,g_i,h_j) は通常微分可能で，局所最適解と大域最適解の概念が重要になる．

---

## 2. 前提知識

* 微分（偏微分，勾配，ヘッセ行列）
* 線形代数（行列固有値，正定値行列）
* 数値計算の基礎（丸め誤差，数値安定性）

---

## 3. 基本概念と表記

* **勾配**: (\nabla f(x))
* **ヘッセ行列**: (\nabla^2 f(x))
* **一階最適性条件**（無制約）: (\nabla f(x^*)=0)
* **二階条件**: 極小であれば (\nabla^2 f(x^*)) は正定値（局所）
* **凸関数**: 凸であれば任意の局所最小は大域最小である（重要）

---

## 4. 非制約最適化：代表アルゴリズム

### 勾配降下法（Gradient Descent）

単純で分かりやすい反復法：

[x_{k+1} = x_k - \alpha_k \nabla f(x_k)]

ステップ長 (\alpha_k) は固定，または線形探索（Armijo, Wolfe 条件）で決める．収束は学習率に敏感である．

### ニュートン法（Newton's Method）

二階情報を用いる．更新式：

[x_{k+1} = x_k - [\nabla^2 f(x_k)]^{-1} \nabla f(x_k)]

高速に二次収束するが，ヘッセ行列の計算・逆行列が高コストである．

### 準ニュートン法（Quasi-Newton, 例：BFGS）

ヘッセ行列の近似を反復的に更新して計算コストを下げる．大規模問題には限定メモリ版（L-BFGS）が有効である．

### モーメンタム，加速法（Nesterov）

勾配に慣性項を加えることで収束を加速する手法群．

---

## 5. 制約付き最適化（代表手法）

### ラグランジュ乗数法と KKT 条件

等式制約付き問題はラグランジュ関数を導入して最適性条件（KKT）を扱う．不等式制約も含めて最適性判定に使う．

### 射影勾配法（Projected Gradient）

簡単な集合（例：凸集合）への射影を繰り返す方法．

### アクティブセット法，Interior‑Point 法

線形・非線形制約の扱いに有効．Interior‑Point は大規模な凸最適化で実用的である．

### ペナルティ法・増加ラグランジュ法（Augmented Lagrangian）

制約違反に対するペナルティを導入し，外側ループでラグランジュ乗数を更新することで扱う．

---

## 6. 数値実装とライブラリ（入門）

簡単な Python 実装例（SciPy を利用）：

```python
import numpy as np
from scipy.optimize import minimize

# Rosenbrock 関数
def rosen(x):
    return 100.0*(x[1]-x[0]**2)**2 + (1-x[0])**2

x0 = np.array([ -1.2, 1.0 ])
res = minimize(rosen, x0, method='BFGS', options={'disp': True})
print(res.x)
```

主要ライブラリ：SciPy (optimize)、CVXOPT、OSQP（2次計画），Ipopt（非線形計画），NLopt など．

---

## 7. 演習問題

1. Rosenbrock 関数の最小化を，勾配降下法・BFGS・Newton 法で実装して比較せよ．収束速度と反復数をプロットせよ．
2. 簡単な等式制約（例：(x_1+x_2=1)）を持つ二変数関数をラグランジュ乗数法で解析的に解け．
3. 凸関数と非凸関数の局所最適解の違いを具体例（図示）で示せ．

---

## 8. 参考文献・学習リソース

* S. Boyd and L. Vandenberghe, *Convex Optimization* — 凸最適化の定番教科書（無料 PDF が公開されている）．
* Nocedal & Wright, *Numerical Optimization* — 数値最適化の標準的教科書．
* SciPy Optimize ドキュメント（チュートリアル）

---
